---
title: SBATCH Usage Examples
author: Woongbae Jeon
date: 2024-04-21
layout: post
---

SBATCH 사용 예시 입니다.  
제공해주신 재준이형 에게 감사의 말씀 드립니다.

- 제출용 script

```bash
#!/bin/bash
# run_bash.sh
#SBATCH --job-name=EEG_Learning
#SBATCH --partition=sbatch
# Specify the node's name
#SBATCH --nodelist=server3
#SBATCH --nodes=1
#SBATCH --output=sbatch.out
#SBATCH --gres=gpu:4
## Command(s) to run (example):

export PATH="/home/jjlee/anaconda3/bin:$PATH"
source ~/.bashrc
source activate eeg
cd /home/jjlee/EEG_Learning/
bash run.sh

# exit 0 # explicitly announce that job has ended
```

Slurm은 제출한 SBATCH script 안에 있는 cmd들을  
사용자가 지정한 리소스 설정으로 실행합니다.  

따라서 실행하고자 하는 task가 여러개 있다면, 위의 예시처럼  
`bash run.sh` 처럼 해당 task들을 여러개의 script로 묶는걸 권장합니다.

- `run.sh`

```bash
cd /home/jjlee/EEG_Learning

taskset --cpu-list 51-58 python3 train_all.py EEG_MAML_model_v2_7shot --dataset EEG --data_dir /data/jjlee_datasets/EEG_datasets/ --steps 1000 --lr 5e-4 --optimizer adamw --gpu_id 0 --spt 7 --qry 15 --batch_size 10 --update_steps 3 --update_steps_test 6 --update_lr 1e-3 --try_n_times 2 --is_maml &

taskset --cpu-list 61-68 python3 train_all.py EEG_MAML_model_v2_5shot --dataset EEG --data_dir /data/jjlee_datasets/EEG_datasets/ --steps 1000 --lr 5e-4 --optimizer adamw --gpu_id 1 --spt 5 --qry 15 --batch_size 10 --update_steps 3 --update_steps_test 6 --update_lr 1e-3 --try_n_times 2 --is_maml &

taskset --cpu-list 71-78 python3 train_all.py EEG_MAML_model_v2_3shot --dataset EEG --data_dir /data/jjlee_datasets/EEG_datasets/ --steps 1000 --lr 5e-4 --optimizer adamw --gpu_id 2 --spt 3 --qry 15 --batch_size 10 --update_steps 3 --update_steps_test 6 --update_lr 1e-3 --try_n_times 2 --is_maml &

taskset --cpu-list 81-88 python3 train_all.py EEG_MAML_model_v2_1shot --dataset EEG --data_dir /data/jjlee_datasets/EEG_datasets/ --steps 1000 --lr 5e-4 --optimizer adamw --gpu_id 3 --spt 1 --qry 15 --batch_size 10 --update_steps 3 --update_steps_test 6 --update_lr 1e-3 --try_n_times 2 --is_maml &

wait
echo "All experiments completed."
```

`taskset` 은 실행하고자 하는 프로세스를 특정 cpu에 배당하는 기능입니다.  
예를 들어, 맨 위의 `taskset --cpu-list 51-58 python3 train_all.py` 는  
해당 서버의 51번~58번, 총 8개의 cpu 에서만 실행됩니다.

배당 가능한, 혹은 배당 받은 cpu 개수보다 더 많은 양을 할당하면 오류가 발생할 수 있습니다.

- GPU 여러개 사용하기

해당 script는 한 개의 sbatch script로 여러개의 gpu를 사용하는 예시를 보여줍니다.

위 `run.sh` 안에서 사용되는 `--gpu_id` 를 참조 바랍니다.  
`--gpu_id` 는 아래와 같이 설정하며, 재준이형이 만든 커스텀 기능이라서  
아래와 같은 원본 코드를 첨부합니다. 참고 바랍니다.

```python
if _name_ == "_main_":
    args, hparams = parse_argument()
    torch.cuda.set_device(args.gpu_id)
    main()
```